% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Stan

Program}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Randomized Time Trial},
  pdfauthor={Michael Betancourt},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Randomized Time Trial}
\author{Michael Betancourt}
\date{August 2024}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
Modeling the outcome of competitions, for example games between
competing sports teams or tests between students and a standardized set
of questions, is a common statistics application. Different types of
competitions, however, are more or less compelling to certain audiences.
In this case study I consider a Bayesian analysis of a somewhat niche
competition that also happens to be particular compelling to the author
-- racing to see who can finish a modified version of a thirty year old
video game as quickly as possible.

\section{Super Metroid Map Randomizer
Races}\label{super-metroid-map-randomizer-races}

In the era of the Super Nintendo Entertainment System® the assets
comprising each video game -- such as code, visuals, and music -- were
stored in the read-only memory, or \textbf{ROM}, of physical cartridges.
\textbf{ROM hacks} rearrange the assets of a particular game, and in
some cases include assets from other games or even entirely new assets,
to create novel gaming experiences. Many popular ROM hacks, for example,
add quality of life features to make older games less frustrating to
play. Others focus on drastically increasing the difficulty of existing
games while still others offer the ability to randomize locations,
items, and more so that each new playthrough is unique.

Super Metroid® was first released for the Super Nintendo Entertainment
System® in 1994. The game's well-designed core mechanics interact
surprisingly well with unintended bugs, resulting in fast-paced and
highly-technical game play that has long been a favorite target of the
ROM hacking community.

One prominent example is the \href{https://maprando.com}{Super Metroid
Map Randomizer} ({``Super Metroid Map Rando,''} n.d.), or
\emph{MapRando} for short. The Super Metroid Map Randomizer is an
\href{https://github.com/blkerby/MapRandomizer}{open source project}
started in 2021 that randomizes individual rooms, items, objectives, and
more while also avoiding any inconsistencies that would prevent players
from completing the game. Randomization options are extensive and can be
configured to control everything from the topology of the room placement
to the difficulty of the techniques needed for completion. Each realized
map is referred to as a \emph{seed} for the seed that initializes the
behavior of the underlying pseudo-random number generator.

By 2024 the project had stimulated a passionate user community that not
only played the games individually but also started to race against each
other to see who could finish a particular seed the fastest. Because
some seeds end up being easier to finish than others the races tend to
be a bit chaotic and consistently entertaining.

Community races are even organized and recorded on the non-commercial
speed running website \href{https://racetime.gg/smr}{racetime.gg}
({``Super Metroid Randomizer \textbar{} Racetime.gg,''} n.d.).
Conveniently this organization makes data on previous races, including
individual entrants and their race outcomes, readily accessible. The
availability of this data in turn puts us in a position to infer and
compare the skill of those entrants and predict the outcome of future
races.

\section{Environment Setup}\label{environment-setup}

Before exploring that data we'll need to set up our local \texttt{R}
environment.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{family=}\StringTok{"serif"}\NormalTok{, }\AttributeTok{las=}\DecValTok{1}\NormalTok{, }\AttributeTok{bty=}\StringTok{"l"}\NormalTok{,}
    \AttributeTok{cex.axis=}\DecValTok{1}\NormalTok{, }\AttributeTok{cex.lab=}\DecValTok{1}\NormalTok{, }\AttributeTok{cex.main=}\DecValTok{1}\NormalTok{,}
    \AttributeTok{xaxs=}\StringTok{"i"}\NormalTok{, }\AttributeTok{yaxs=}\StringTok{"i"}\NormalTok{, }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{library}\NormalTok{(rstan)}
\FunctionTok{rstan\_options}\NormalTok{(}\AttributeTok{auto\_write =} \ConstantTok{TRUE}\NormalTok{)            }\CommentTok{\# Cache compiled Stan programs}
\FunctionTok{options}\NormalTok{(}\AttributeTok{mc.cores =}\NormalTok{ parallel}\SpecialCharTok{::}\FunctionTok{detectCores}\NormalTok{()) }\CommentTok{\# Parallelize chains}
\NormalTok{parallel}\SpecialCharTok{:::}\FunctionTok{setDefaultClusterOptions}\NormalTok{(}\AttributeTok{setup\_strategy =} \StringTok{"sequential"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To facilitate the implementation of Bayesian inference we'll also need
my recommended
\href{https://github.com/betanalpha/mcmc_diagnostics}{diagnostics} and
\href{https://github.com/betanalpha/mcmc_visualization_tools}{visualization}
tools.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util }\OtherTok{\textless{}{-}} \FunctionTok{new.env}\NormalTok{()}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}mcmc\_analysis\_tools\_rstan.R\textquotesingle{}}\NormalTok{, }\AttributeTok{local=}\NormalTok{util)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}mcmc\_visualization\_tools.R\textquotesingle{}}\NormalTok{, }\AttributeTok{local=}\NormalTok{util)}
\end{Highlighting}
\end{Shaded}

\section{Data Exploration}\label{data-exploration}

To assemble the full data set I programmatically scraped
\texttt{https://racetime.gg/smr} for all races with the title
\texttt{Map\ Rando} that also include a link to the MapRando
configuration in their description. This then allowed me to collect
additional information on the MapRando version while also restricting
consideration to only those seeds with a \texttt{Hard} skill assumption
and \texttt{Tricky} item progression setting.

For each valid race I then scraped information on the individual
participants, in particular whether they finished the race or forfeited
and, if they finished, what their finish time was in seconds. Forfeits
are also referred to as ``did not finish'' or ``DNF''. Although forfeit
times are available on \texttt{https://racetime.gg/smr} interactively
they are difficult to extract programmatically and I consequently did
not include them.

Following the \texttt{racetime.gg} terminology I will refer to
individual participants in a race as \textbf{entrants} and their
participation into a particular race as an \textbf{entrance}. For
programming convenience I encoded the individual entrant usernames into
sequential numerical labels that can also be used for indexing.

Each race consists of a variable number of entrances, with each entrance
resulting in either a finish time or a forfeit. To accommodate this
ragged structure I organized the finish entrances and forfeit entrances
for all races into single arrays that are complemented with indexing
arrays for straightforward retrieval of individual race information.

The data collection scripts, translation between entrant indices and
usernames, and final data are all accessible in the
\href{https://github.com/betanalpha/quarto_chapters/tree/main/case_studies/racing/data}{GitHub
repository} for this chapter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/entrant\_level\_defs.csv"}\NormalTok{)}

\NormalTok{race\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/race\_info.csv"}\NormalTok{)}
\NormalTok{race\_entrant\_f\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/race\_entrant\_f\_info.csv"}\NormalTok{)}
\NormalTok{race\_entrant\_dnf\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/race\_entrant\_dnf\_info.csv"}\NormalTok{)}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"N\_races"} \OtherTok{=} \FunctionTok{nrow}\NormalTok{(race\_info),}
             \StringTok{"N\_entrants"} \OtherTok{=} \FunctionTok{nrow}\NormalTok{(entrant\_info),}
             \StringTok{"race\_N\_entrants\_f"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f,}
             \StringTok{"race\_N\_entrants\_dnf"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
             \StringTok{"race\_f\_start\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs,}
             \StringTok{"race\_f\_end\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs,}
             \StringTok{"race\_dnf\_start\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_dnf\_start\_idxs,}
             \StringTok{"race\_dnf\_end\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_dnf\_end\_idxs,}
             \StringTok{"race\_entrant\_f\_idxs"} \OtherTok{=}\NormalTok{ race\_entrant\_f\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs,}
             \StringTok{"race\_entrant\_f\_times"} \OtherTok{=}\NormalTok{  race\_entrant\_f\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
             \StringTok{"N\_entrances\_fs"} \OtherTok{=} \FunctionTok{length}\NormalTok{(race\_entrant\_f\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs),}
             \StringTok{"race\_entrant\_dnf\_idxs"} \OtherTok{=}\NormalTok{ race\_entrant\_dnf\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs,}
             \StringTok{"N\_entrances\_dnfs"} \OtherTok{=} \FunctionTok{length}\NormalTok{(race\_entrant\_dnf\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs))}
\end{Highlighting}
\end{Shaded}

Altogether the data spans 192 races across the first eight months of
2024.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}\%i total races\textquotesingle{}}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{N\_races))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
192 total races
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}First Race: \%s\textquotesingle{}}\NormalTok{, race\_info}\SpecialCharTok{$}\NormalTok{race\_datetimes[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
First Race: 2024-01-09T21:39:16.610866+00:00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}Last Race: \%s\textquotesingle{}}\NormalTok{,}
\NormalTok{            race\_info}\SpecialCharTok{$}\NormalTok{race\_datetimes[}\FunctionTok{length}\NormalTok{(race\_info}\SpecialCharTok{$}\NormalTok{race\_datetimes)]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Last Race: 2024-07-27T23:28:49.606056+00:00
\end{verbatim}

Those races included 107 distinct entrants.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}\%i total entrants\textquotesingle{}}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{N\_entrants))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
107 total entrants
\end{verbatim}

While the majority of races include at least five entrants some include
over thirty.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f }\SpecialCharTok{+}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                    \DecValTok{0}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{3}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Total Entrants Per Race"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-6-1.pdf}

Similarly most races see most entrants finishing but some races,
presumable using more difficult seeds, can see over half of the entrants
forfeit.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf }\SpecialCharTok{/}
\NormalTok{                    (data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f }\SpecialCharTok{+}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf),}
                    \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.02}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Proportion of Forfeits Per Race"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-7-1.pdf}

The finish times across races vary substantially, peaking near an hour
but stretching from half an hour all the way to multiple hours. This
suggests that player skill, seed difficulty, or some combination of the
two, is highly variable from race to race.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{10}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Finish Time (minutes)"}\NormalTok{, }\AttributeTok{main=}\StringTok{"All Races"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-8-1.pdf}

If we isolate the finish times for a few entrants near the top of the
\texttt{https://racetime.gg/smr} leader boards then we see much less
variability, especially in the upper tail.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{91}\NormalTok{)) \{}
\NormalTok{  times }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[}\FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)]}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(times }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{220}\NormalTok{, }\DecValTok{10}\NormalTok{,}
                      \AttributeTok{xlab=}\StringTok{"Finish Time (minutes)"}\NormalTok{,}
                      \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-9-1.pdf}

Overall participation and proportion of forfeits exhibits its own
heterogeneity across the individual entrants.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{entrant\_f\_idxs }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
  \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{\}}

\NormalTok{entrant\_dnf\_idxs }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
  \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{\}}

\NormalTok{N\_entrant\_f\_races }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                            \ControlFlowTok{function}\NormalTok{(e) }\FunctionTok{length}\NormalTok{(}\FunctionTok{entrant\_f\_idxs}\NormalTok{(e)))}
\NormalTok{N\_entrant\_dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                              \ControlFlowTok{function}\NormalTok{(e) }\FunctionTok{length}\NormalTok{(}\FunctionTok{entrant\_dnf\_idxs}\NormalTok{(e)))}

\FunctionTok{barplot}\NormalTok{(N\_entrant\_f\_races,}
        \AttributeTok{space=}\DecValTok{0}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark\_teal, }\AttributeTok{border=}\StringTok{"white"}\NormalTok{,}
        \AttributeTok{xlab=}\StringTok{"Entrant Index"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Total Races Finished"}\NormalTok{)}

\FunctionTok{barplot}\NormalTok{(N\_entrant\_dnf\_races,}
        \AttributeTok{space=}\DecValTok{0}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark\_teal, }\AttributeTok{border=}\StringTok{"white"}\NormalTok{,}
        \AttributeTok{xlab=}\StringTok{"Entrant Index"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Total Races Forfeited"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-10-1.pdf}

There are many more ways that we could dive further into the data here,
but without domain expertise to guide us it's easy to get lost. Instead
let's leverage what understanding we've developed into an initial model.

\section{Model Development}\label{model-development}

To make the modeling process as manageable as possible we will start
simple and then add features iteratively.

\subsection{Model 1}\label{model-1}

To begin let's ignore forfeits altogether and instead focus on modeling
the finish times of the entrants who do not forfeit in each race.

One of the challenging aspects of modeling races in general is that
individual entrant behavior can depend on their position at any given
time. For example an entrant in first place might slow their pace to
stay just ahead of the entrant in second place, while racers in lower
places might play more aggressively in an attempt to catch up. While
some MapRando race entrants live-stream their play publicly the
community largely follows the rules of \texttt{https://racetime.gg/smr}
which disallow entrants from following the progress of any other
entrants.

Consequently entrants are mostly ignorant of their position during
races, at least until the first entrants finish and post their finish
times on the active \texttt{https://racetime.gg/smr} race page. This
suggest that modeling the finish time of each entrant independently of
the other entrants, without having to worry about interactions within
each race, is a reasonable approximation to the true race dynamics.

Now a particularly crude model of independent finish times might assume
that the finish times across all races concentrate around some common
baseline value, \[
\mu = t_{\mathrm{baseline}} = \exp(\gamma) \cdot 1 \text{ second}.
\] Not all races, however, are the same.

For example some seeds result in map layouts that require traveling
longer distances than others and some require spending difficult
techniques that usually take longer to complete than others. We could
account for this heterogeneity with a separate baseline finish time for
each seed, but we could also account for it by proportionally modifying
the common baseline, \begin{align*}
\mu_{s}
&=
t_{\mathrm{baseline}} \cdot \delta_{\mathrm{difficulty}, s}
\\
&=
\exp(\gamma) \cdot \exp( \lambda_{\mathrm{difficulty}, s} )
\cdot 1 \text{ second}
\\
&=
\exp(\gamma + \lambda_{\mathrm{difficulty}, s}) \cdot 1 \text{ second}.
\end{align*}

Similarly not all entrants are the same. The entrants who are more
experienced with Super Metroid® game play in general, and MapRando game
play in particular, should be able to finish a random seed faster than
those who are less experienced. Again we can model this with a
proportional modification to the common baseline, \begin{align*}
\mu_{se}
&=
t_{\mathrm{baseline}}
\cdot \delta_{\mathrm{difficulty}, s}
\cdot \frac{1}{\delta_{\mathrm{skill}, e}}
\\
&=
\exp(\gamma)
\cdot \exp( \lambda_{\mathrm{difficulty}, s} )
\cdot \frac{1}{\exp( \lambda_{\mathrm{skill}, e} ) }
\cdot 1 \text{ second}
\\
&=
\exp(\gamma + \lambda_{\mathrm{difficulty}, s} - \lambda_{\mathrm{skill}, e})
\cdot 1 \text{ second}.
\end{align*}

Note that this model is an example of an \textbf{adversarial model}
where the result of a competition between two agents concentrates around
some central value \(\mu\) that increases when the ability of the first
agent, \(\lambda_{1}\), is larger than the second, \(\lambda_{2}\), and
decreases when the ability of the second agent is larger than the first,
\[
\mu = f( \lambda_{1} - \lambda_{2} ).
\] Comparing this model to other adversarial models, such as
Bradley-Terry models and item response theory models, can be a
productive way to motivate useful model expansions. For example if the
MapRando algorithm ever suffered from weird bugs that sometimes resulted
in seeds insensitive to player skill then we could introduce a
discrimination parameter for each race, similar to some popular item
response theory models, \[
\mu_{se}
=
\exp(
\gamma
+ \alpha_{s} \cdot (  \lambda_{\mathrm{difficulty}, s}
                    - \lambda_{\mathrm{skill}, e}) )
\cdot 1 \text{ second}.
\] The smaller \(\alpha_{s}\) is the less sensitive the finish times for
the given seed will be to the contrast between seed difficulty and
entrant skill.

To complete our observational model we need to model the variation of
finish times around these baselines. One immediate possibility is the
gamma family of probability density functions, not in its conventional
parameterizations but rather in its mean-dispersion parameterization.
For example the gamma family of probability density functions is
typically parameterized in terms of a shape parameter \(\alpha\) and a
scale parameter \(\beta\). We can also parameterize this same family in
terms of a location parameter \[
\mu = \text{mean}(\alpha, \beta) = \frac{\alpha}{\beta},
\] and a dispersion parameter \begin{align*}
\psi
&=
\frac{ \text{variance}(\alpha, \beta) }{ \text{mean}^{2}(\alpha, \beta) }
\\
&=
\frac{\alpha}{\beta^{2}} \left( \frac{\beta}{\alpha} \right)^{2}
\\
&=
\frac{1}{\alpha}.
\end{align*} We can then define an appropriate observational model by
replacing the location parameter \(\mu\) with the seed-entrant baseline
\(\mu_{se}\) for each entrant in a particular race.

Finally in order to elevate our observational model to a full Bayesian
model we need to specify a prior model over our model configuration
variables. Here we'll assume that the prior model is built up from
independent component prior models for each parameter.

To avoid unrealistically fast and slow races let's constrain the
baseline finish time to \begin{alignat*}{5}
& 1800 \text{ seconds} &
& \lessapprox &
& \quad\quad\;\; t_{\mathrm{baseline}} &
& \lessapprox &
& \, 5400 \text{ seconds}
\\
& 1800 \text{ seconds} &
& \lessapprox &
& \, \exp(\gamma) \cdot 1 \text{ second} \, &
& \lessapprox &
& \, 5400 \text{ seconds}
\\
& 1800 &
& \lessapprox &
& \quad\quad\; \exp(\gamma) &
& \lessapprox &
& \, 5400
\\
& \log 1800 &
& \lessapprox &
& \quad\quad\quad\;\;\, \gamma &
& \lessapprox &
& \log 5400.
\end{alignat*} We can ensure that 98\% of the prior probability is
contained within these bounds with the prior model \begin{align*}
p( \gamma )
&=
\text{normal} \left(
\gamma \;\, \bigg| \;\, \frac{\log 5400 + \log 1800}{2},
                        \frac{1}{2.32} \frac{\log 5400 - \log 1800}{2} \right)
\\
&= \text{normal}( \gamma \mid 8.045, 0.237).
\end{align*} Note that this prior model doesn't suppress finish times
below 30 minutes and above 90 minutes, just the central baseline. The
variation of the gamma observational model will allow for much smaller
and much larger finish times.

Similarly it would be a bit extreme if seed difficulty or entrant skill
modified the baseline by more than a factor of two, \begin{align*}
\frac{1}{2} \lessapprox &\delta \lessapprox 2
\\
\log \frac{1}{2} \lessapprox &\lambda \lessapprox \log 2
\\
- \log 2 \lessapprox &\lambda \lessapprox \log 2.
\end{align*} A reasonable prior that achieves this soft containment is
then \begin{align*}
p( \lambda )
&=
\text{normal} \left(
\lambda \;\, \bigg| \;\, \frac{\log 2 + (-\log 2)}{2},
                         \frac{1}{2.32} \frac{\log 2 - (-\log 2)}{2} \right)
\\
&=
\text{normal} \left(
\lambda \;\, \bigg| \;\, 0, \frac{1}{2.32} \, \log 2\right)
\\
&= \text{normal}( \lambda \mid 0, 0.299).
\end{align*}

Lastly we need to consider the dispersion strength \(\psi\). Here let's
suppress model configurations where the variance would exceed the
squared mean, \begin{align*}
0 \lessapprox
&\frac{ \text{variance}(\alpha, \beta) }{ \text{mean}^{2}(\alpha, \beta) }
\lessapprox 1
\\
0 \lessapprox & \quad\quad\;\;\;\, \psi \quad\quad\;\;\;\,  \lessapprox 1.
\end{align*} One way to achieve this soft containment is with the prior
model \[
p( \psi )
= \text{half-normal} \left( \psi \;\, \bigg| \;\, 0, \frac{1}{2.57} \right)
= \text{half-normal} \left( \psi \;\, \bigg| \;\, 0, 0.389 \right).
\]

We can now implement our full Bayesian model as a Stan program, plug in
the observed data, and give Stan's Hamiltonian Monte Carlo sampler a
chance at exploring the posterior distribution.

\begin{codelisting}

\caption{\texttt{model1.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of gamma family}
  \DataTypeTok{real}\NormalTok{ gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ gamma\_lpdf(x | inv(psi), inv(mu * psi));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ gamma\_rng(inv(psi), inv(mu * psi));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Total number of entrant finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ gamma;                       }\CommentTok{// Log baseline finish time (log seconds)}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ difficulties; }\CommentTok{// Seed difficulties}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ skills;    }\CommentTok{// Entrant skills}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi;                }\CommentTok{// Gamma dispersion configuration}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  gamma \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);    }\CommentTok{// log(1800 s) \textless{} gamma \textless{} log(5400 s)}
\NormalTok{  difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.299}\NormalTok{); }\CommentTok{// {-}log(2) \textless{}\textasciitilde{} difficulties \textless{}\textasciitilde{} +log(2)}
\NormalTok{  skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.299}\NormalTok{);       }\CommentTok{// {-}log(2) \textless{}\textasciitilde{}    skills    \textless{}\textasciitilde{} +log(2)}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);          }\CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + difficulties[r] {-} skills[entrant\_idx]);}
\NormalTok{      entrant\_f\_times[n] \textasciitilde{} gamma\_md(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}

    \CommentTok{// Finish time predictions conditioned on not forfeiting}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + difficulties[r] {-} skills[entrant\_idx]);}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = gamma\_md\_rng(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model1.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The warnings indicate strong auto-correlations in \(\gamma\), the
difficulty parameters for some of the seeds, and the skill parameters
for some of the entrants.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics1 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples1 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples1,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}skills\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{summarize\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands gamma, difficulties[140], difficulties[143], skills[1],
skills[2], skills[3], skills[4], skills[5], skills[6], skills[12],
skills[16], skills[17], skills[18], skills[19], skills[22], skills[24],
skills[26], skills[29], skills[30], skills[31], skills[34], skills[35],
skills[36], skills[43], skills[44], skills[45], skills[48], skills[49],
skills[51], skills[55], skills[57], skills[58], skills[59], skills[60],
skills[61], skills[62], skills[64], skills[65], skills[68], skills[69],
skills[70], skills[71], skills[72], skills[73], skills[78], skills[81],
skills[83], skills[84], skills[88], skills[90], skills[91], skills[93],
skills[94], skills[95], skills[96], skills[98], skills[99],
skills[100], skills[105], skills[107] triggered diagnostic warnings.

The expectands gamma, difficulties[140], difficulties[143], skills[1],
skills[2], skills[3], skills[4], skills[5], skills[6], skills[12],
skills[16], skills[17], skills[18], skills[19], skills[22], skills[24],
skills[26], skills[29], skills[30], skills[31], skills[34], skills[35],
skills[36], skills[43], skills[44], skills[45], skills[48], skills[49],
skills[51], skills[55], skills[57], skills[58], skills[59], skills[60],
skills[61], skills[62], skills[64], skills[65], skills[68], skills[69],
skills[70], skills[71], skills[72], skills[73], skills[78], skills[81],
skills[83], skills[84], skills[88], skills[90], skills[91], skills[93],
skills[94], skills[95], skills[96], skills[98], skills[99],
skills[100], skills[105], skills[107] triggered hat{ESS} warnings.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

Fortunately the empirical effective sample sizes are not quite small
enough, and hence the auto-correlations are not quite large enough, to
compromise the accuracy of our Markov chain Monte Carlo estimators, just
limit their precision. It's only when the empirical effective sample
sizes dip below ten or so that we really need to be worried.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{min\_ess\_hats }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_ess\_hats}\NormalTok{(base\_samples)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(min\_ess\_hats, }\DecValTok{0}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                    \AttributeTok{xlab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Smallest Empirical Effective Sample Size}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
                                \StringTok{"Across All Markov Chains For Each Expectand"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, values): 212 values (70.4%)
fell below the binning.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\DecValTok{100}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lty=}\DecValTok{3}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-13-1.pdf}

This behavior is unfortunately not uncommon with adversarial models.
Without enough data the model is vulnerable to degeneracies where some
of the additive terms vary without changing their sum, tracing out a
narrow plane of consistent model configurations that can be difficult to
explore efficiently.

Indeed we see that the consistent values of \(\gamma\) are negatively
correlated, albeit weakly, with the seed difficulties: \(\gamma\) can
increase without changing the baseline finish times so long as all of
the seed difficulties decrease at the same time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_div\_pairs}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{),}
                    \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[84]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}difficulties[90]\textquotesingle{}}\NormalTok{,}
                      \StringTok{\textquotesingle{}difficulties[147]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}difficulties[165]\textquotesingle{}}\NormalTok{),}
\NormalTok{                    samples1, diagnostics1)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-14-1.pdf}

On the other hand \(\gamma\) is positively correlated with the
individual skill parameters. In this case increases to \(\gamma\) and
all of the entrant skills cancel to give the same baseline finish times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_div\_pairs}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{),}
                    \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}skills[1]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}skills[30]\textquotesingle{}}\NormalTok{,}
                      \StringTok{\textquotesingle{}skills[55]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}skills[107]\textquotesingle{}}\NormalTok{),}
\NormalTok{                    samples1, diagnostics1)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-15-1.pdf}

If we wanted to be careful then we could run longer Markov chains to
compensate for the large auto-correlations and ensure more well-behaved
Markov chain Monte Carlo estimation. As this is our first model,
however, let's just push ahead to the posterior retrodictive checks.

There are a lot of summary statistics that we might consider for our
visual posterior retrodictive checks. For example we could use a
histogram summary statistic that aggregates the finish times across all
races. Here we see a pretty strong retrodictive tension with the
observed finish times exhibiting stronger skewness than what the
posterior predictive distribution can accommodate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples1, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-16-1.pdf}

This tension could be due to inadequacy of the gamma observational
model, but it could also be a consequence of poorly modeling the
heterogeneity in seed difficulties and entrant skills. One way to
explore these possibilities is to separate the histogram summary
statistic by race and entrant.

Here there doesn't seem to be any substantial retrodictive tension in
the finish times for a few arbitrarily selected races.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples1, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 49 predictive values (0.1%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 108 predictive values (0.2%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-17-1.pdf}

Similarly the finish time behaviors for a few spot-checked entrants are
consistent between the observed data and our posterior predictions. One
might argue that the observed behavior for entrant 93 is slightly
heavier-tailed than the posterior predictions but the disagreement is
relatively weak.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples1, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 1 predictive value (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 11 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-18-1.pdf}

If we really wanted to be thorough then we would need to examine the
behavior of the hundreds of finish time histograms across all of the
individual races and all of the individual entrants. Based on the
reasonable behavior of the few spot checks that we've performed here,
however, let's see if changing the observational model addresses the
issue.

\subsection{Model 2}\label{model-2}

The gamma family of probability density functions are naturally
complemented with the inverse gamma family of probability density
functions. Because the gamma probability density functions exhibit
heavier tails towards zero and lighter tails towards infinity their
\emph{peaks} skew towards larger values. On the other hand the inverse
gamma probability density functions exhibit lighter tails towards zero
and heavier tails towards infinity, resulting in \emph{peaks} that skew
towards smaller values. This conveniently contrasting behavior might be
exactly what we need to address the retrodictive tension in our first
model.

In order to build an inverse gamma observational model we need to
engineer a location-dispersion parameterization. The inverse gamma
family, like the gamma family, is typically parameterized in terms of a
shape parameter \(\alpha\) and a scale parameter \(\beta\). At the same
time we can also parameterize the family in terms of a location
parameter \[
\mu = \text{mean}(\alpha, \beta) = \frac{\beta}{\alpha - 1}
\] and a dispersion parameter \begin{align*}
\psi
&=
\frac{ \text{variance}(\alpha, \beta) }{ \text{mean}^{2}(\alpha, \beta) }
\\
&=
\frac{1}{\alpha - 2} \left( \frac{ \beta }{ \alpha - 1} \right)^{2}
\left( \frac{ \alpha - 1 }{ \beta } \right)^{2}
\\
&=
\frac{1}{\alpha - 2}.
\end{align*}

Let's try swapping the gamma observational model with an inverse gamma
observational model.

\begin{codelisting}

\caption{\texttt{model2.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Total number of entrant finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ gamma;                       }\CommentTok{// Log baseline finish time (log seconds)}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ difficulties; }\CommentTok{// Seed difficulties}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ skills;    }\CommentTok{// Entrant skills}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi;                }\CommentTok{// Inverse gamma dispersion configuration}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  gamma \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);    }\CommentTok{// log(1800 s) \textless{} gamma \textless{} log(5400 s)}
\NormalTok{  difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.299}\NormalTok{); }\CommentTok{// {-}log(2) \textless{}\textasciitilde{} difficulties \textless{}\textasciitilde{} +log(2)}
\NormalTok{  skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.299}\NormalTok{);       }\CommentTok{// {-}log(2) \textless{}\textasciitilde{}    skills    \textless{}\textasciitilde{} +log(2)}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);          }\CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + difficulties[r] {-} skills[entrant\_idx]);}
\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}

    \CommentTok{// Finish time predictions conditioned on not forfeiting}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + difficulties[r] {-} skills[entrant\_idx]);}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model2.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The computational diagnostics continue to show strong auto-correlation
warnings but nothing else.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics2 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples2 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples2,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}skills\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{summarize\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands gamma, difficulties[140], difficulties[147], skills[1],
skills[2], skills[3], skills[4], skills[5], skills[6], skills[12],
skills[16], skills[17], skills[18], skills[19], skills[22], skills[24],
skills[26], skills[28], skills[29], skills[30], skills[31], skills[34],
skills[35], skills[36], skills[43], skills[44], skills[45], skills[48],
skills[49], skills[51], skills[55], skills[57], skills[58], skills[59],
skills[60], skills[61], skills[62], skills[64], skills[65], skills[68],
skills[69], skills[70], skills[71], skills[72], skills[73], skills[78],
skills[81], skills[88], skills[90], skills[91], skills[93], skills[94],
skills[95], skills[96], skills[98], skills[99], skills[100],
skills[105], skills[107] triggered diagnostic warnings.

The expectands gamma, difficulties[140], difficulties[147], skills[1],
skills[2], skills[3], skills[4], skills[5], skills[6], skills[12],
skills[16], skills[17], skills[18], skills[19], skills[22], skills[24],
skills[26], skills[28], skills[29], skills[30], skills[31], skills[34],
skills[35], skills[36], skills[43], skills[44], skills[45], skills[48],
skills[49], skills[51], skills[55], skills[57], skills[58], skills[59],
skills[60], skills[61], skills[62], skills[64], skills[65], skills[68],
skills[69], skills[70], skills[71], skills[72], skills[73], skills[78],
skills[81], skills[88], skills[90], skills[91], skills[93], skills[94],
skills[95], skills[96], skills[98], skills[99], skills[100],
skills[105], skills[107] triggered hat{ESS} warnings.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

Again the auto-correlations are not strong enough to undermine our
Markov chain Monte Carlo estimators entirely. Indeed they seem to be a
bit better than before.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{min\_ess\_hats }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_ess\_hats}\NormalTok{(base\_samples)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(min\_ess\_hats, }\DecValTok{0}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                    \AttributeTok{xlab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Smallest Empirical Effective Sample Size}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
                                \StringTok{"Across All Markov Chains For Each Expectand"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, values): 214 values (71.1%)
fell below the binning.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\DecValTok{100}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lty=}\DecValTok{3}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-21-1.pdf}

It looks like this may have done the trick. The observed and posterior
predictive behavior of the aggregate finish time histogram is a bit more
consistent than it was in our first model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples2, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-22-1.pdf}

The retrodictive agreement in the individual race finish time histograms
is similar to what we saw above. In particular no new retrodictive
tensions have arisen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples2, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 71 predictive values (0.2%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 133 predictive values (0.2%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 4 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-23-1.pdf}

Interestingly the heavier tail of the inverse gamma family appears to
allow the posterior predictive behavior for entrant 93 to spread out
further and better match the observed behavior.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples2, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 9 predictive values (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 2 predictive values (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 11 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-24-1.pdf}

With no immediate reason to doubt our modeling assumptions we can
finally move on to investigating our posterior inferences. The marginal
posterior distributions for \(\gamma\) and \(\psi\) look reasonable,
with both strongly contracting within the prior model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"gamma"}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"psi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-25-1.pdf}

While the values of the individual seed difficulties all seem reasonable
there does appear to be an unexpected pattern across the races.
Initially the difficulties systematically decay before flatting out.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Difficulty"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-26-1.pdf}

On the other hand the entrant skills exhibit both reasonable values and
no systematic patterns.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Skill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-27-1.pdf}

Let's go back to the difficulties and consider why we might see a
pattern like that. Notice that the seeds for each race are ordered by
the time at which the race occurred. Consequently the pattern we see is
likely a relationship between seed difficulty and time.

One possibility is that the seed difficulties are actually getting
easier. Another possibility is that our inferences for the seed
difficulties are actually compensating for other time-dependent
behaviors in these races that the model cannot otherwise accommodate.
For example if the entire racing community was gradually getting better
at the game then the entrant skills would improve with time. Because our
model assumes static skills, however, this improvement could manifest
only as decreasing seed difficulties.

In order to distinguish between these possible hypotheses let's dive
into this inferential behavior a bit deeper. If the MapRando code were
static then it would be natural to assume that the seed difficulties
scatter around some constant baseline. The MapRando code, however, is
not static and has in fact undergone consistent develop throughout 2024.
Fortunately the code version of each seed is included in our data, and
we can visualize the MapRando development by overlaying the difficulties
with the version numbers.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Difficulty"}\NormalTok{)}

\NormalTok{text\_versions }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"105"}\NormalTok{, }\StringTok{"108"}\NormalTok{, }\StringTok{"109"}\NormalTok{, }\StringTok{"111"}\NormalTok{,}
                   \StringTok{"112 }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{(DEV}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{)"}\NormalTok{, }\StringTok{"112"}\NormalTok{, }\StringTok{"113 }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{(DEV}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{)"}\NormalTok{, }\StringTok{"113"}\NormalTok{)}
\NormalTok{num\_versions }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{105}\NormalTok{, }\DecValTok{108}\NormalTok{, }\DecValTok{109}\NormalTok{, }\DecValTok{111}\NormalTok{, }\FloatTok{111.5}\NormalTok{, }\DecValTok{112}\NormalTok{, }\FloatTok{112.5}\NormalTok{, }\DecValTok{113}\NormalTok{)}
\NormalTok{versions }\OtherTok{\textless{}{-}}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{versions}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(text\_versions)) \{}
\NormalTok{  versions }\OtherTok{\textless{}{-}} \FunctionTok{gsub}\NormalTok{(text\_versions[n], num\_versions[n], versions)}
\NormalTok{\}}
\NormalTok{versions }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(versions)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{new=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\DecValTok{0}\NormalTok{, }\AttributeTok{type=}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{, }\AttributeTok{axes=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{bty =} \StringTok{"n"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{""}\NormalTok{, }\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{N\_races),}
     \AttributeTok{ylab =} \StringTok{""}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{104}\NormalTok{, }\DecValTok{114}\NormalTok{))}

\NormalTok{plot\_xs }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races, }\ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{c}\NormalTok{(r }\SpecialCharTok{{-}} \FloatTok{0.5}\NormalTok{, r }\SpecialCharTok{+} \FloatTok{0.5}\NormalTok{))}
\FunctionTok{dim}\NormalTok{(plot\_xs) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2} \SpecialCharTok{*}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_races)}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
\NormalTok{  idx1 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ r }\SpecialCharTok{{-}} \DecValTok{1}
\NormalTok{  idx2 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ r}
  \FunctionTok{lines}\NormalTok{(plot\_xs[}\DecValTok{1}\NormalTok{, idx1}\SpecialCharTok{:}\NormalTok{idx2], }\FunctionTok{rep}\NormalTok{(versions[r], }\DecValTok{2}\NormalTok{), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\NormalTok{\}}

\FunctionTok{mtext}\NormalTok{(}\StringTok{"Version"}\NormalTok{, }\AttributeTok{side=}\DecValTok{4}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal, }\AttributeTok{line=}\DecValTok{3}\NormalTok{, }\AttributeTok{las=}\DecValTok{0}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{4}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{104}\NormalTok{, }\DecValTok{114}\NormalTok{), }\AttributeTok{las=}\DecValTok{1}\NormalTok{,}
     \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal, }\AttributeTok{col.axis=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal)}

\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\FloatTok{16.5}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\FloatTok{87.5}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-28-1.pdf}

Indeed many of the prominent patterns in seed difficulty over time
perfectly line up with the transition from one version to another. In
hindsight this is completely reasonable as each version improves the
randomization logic to be more consistent and easier for experienced
players to manage, especially in the earlier versions.

What about the hypothesis of improving entrant skills? If entrant skills
were improving then it would be reasonable to expect systematic patterns
between entrant skill and their overall experience with MapRando. While
we do not have access to any exact quantification of experience we can
consider proxies, such as the total number of race entrances. In
particular while entrants might play MapRando, and gain experience,
outside of official races that play time is likely to at least somewhat
scale with the number of race entrances.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{total\_entrances }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs)}
\NormalTok{sorted\_entrances }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{sort}\NormalTok{(total\_entrances))}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(sorted\_entrances}\SpecialCharTok{$}\NormalTok{Var1,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrants Ordered By Total Entrances"}\NormalTok{,}
                                     \AttributeTok{xticklabs=}\NormalTok{sorted\_entrances}\SpecialCharTok{$}\NormalTok{Var1,}
                                     \AttributeTok{ylab=}\StringTok{"Skill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-29-1.pdf}

The most striking pattern that we see is that the \emph{uncertainty} in
the entrant skill inferences decreases with increasing participation,
which is just a consequence of having more data from which to learn.
Beyond the decreasing uncertainty there might also be a mild increase in
skill for the most experienced players.

That said this increase is not necessarily tied to increased experience.
For example entrant skills might be fixed with more skilled players just
enjoying the MapRando races more and hence playing more.

In order to distinguish between these possibilities we would need to
start investigating how the behavior for a single entrant changes with
increasing experience. If entrant skills increased enough, for instance,
then we would see the finish times for a particular entrant
systematically decrease with an increasing number of entrances.

Here let's look at entrant 65.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{completion\_times }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
\NormalTok{  N\_previous\_races }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(cum\_completed\_races)}

\NormalTok{  entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs[entrant\_idxs]) \{}
\NormalTok{    entrant\_idx }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs[entrant\_idxs] }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{    time }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r] }\SpecialCharTok{+}\NormalTok{ entrant\_idx }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}

    \ControlFlowTok{if}\NormalTok{ (N\_previous\_races }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(cum\_completed\_races,}
\NormalTok{                               cum\_completed\_races[N\_previous\_races] }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{    completion\_times }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(completion\_times, time)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \ControlFlowTok{if}\NormalTok{ (N\_previous\_races }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(cum\_completed\_races,}
\NormalTok{                               cum\_completed\_races[N\_previous\_races])}
\NormalTok{      completion\_times }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(completion\_times,}
\NormalTok{                            completion\_times[N\_previous\_races])}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(cum\_completed\_races, completion\_times }\SpecialCharTok{/} \DecValTok{60}\NormalTok{,}
     \AttributeTok{pch=}\DecValTok{16}\NormalTok{, }\AttributeTok{cex=}\FloatTok{1.0}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
     \AttributeTok{xlab=}\StringTok{"Total Entrances"}\NormalTok{,}
     \AttributeTok{ylab=}\StringTok{"Completion Time (minutes)"}\NormalTok{,}
     \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-30-1.pdf}

While there might be a small reduction in the \emph{variation} of finish
times there doesn't seem to be any systematic increase or decrease in
the mean. That's not to say that skills don't improve, just that they're
not improving strongly enough to manifest in this particular
visualization.

Overall the development of the MapRando code offers a satisfying
explanation for the patterns we see the in seed difficulties. That said
it's always helpful to keep the other hypotheses in mind, especially if
we are able to collect more data in the future.

\subsection{Model 3}\label{model-3}

For our next model let's consider forfeits. The danger with ignoring
forfeits is that if the forfeit probability is coupled with entrant
skill then inferences from the finish times alone will give us a biased
view of those skills.

One possible assumption is that forfeits are completely random. For
example entrants could forfeit mostly due to unexpected events that
arise during each race that have nothing to do with their performance.
In this case we could still extract information from the forfeit times
because we can lower bound what the finish time would have been,
\begin{align*}
p(t_{\mathrm{forfeit}} \mid \mu_{se}, \psi)
&=
\pi( \, [ t_{\mathrm{forfeit}}, \infty ) \, \mid \mu_{se}, \psi)
\\
&=
\int_{0}^{t_{\mathrm{forfeit}}} \mathrm{d} t \,
\text{inv-gamma}(t \mid \mu_{se}, \psi)
\\
&=
1 - \Pi_{\text{inv-gamma}}(t_{\mathrm{forfeit}} \mid \mu_{se}, \psi).
\end{align*} Unfortunately while forfeit times are recorded they are
difficult to programmatically access from
\texttt{https://racetime.gg/smr}.

Forfeiting, however, is unlikely to be completely random. Entrants are
more likely to forfeit when they're frustrated by the overall
difficulty, for example when they get lost in a complex map layout or
die at an inopportune point and lose too much progress. This suggests
that \(p(t_{\mathrm{forfeit}})\) should depend on the contrast between
seed difficulty and entrant skill, \[
p(t_{\mathrm{forfeit}} \mid \lambda_{\mathrm{difficulty}, s},
                            \lambda_{\mathrm{skill}, e})
=
f(\lambda_{\mathrm{difficulty}, s} - \lambda_{\mathrm{skill}, e}).
\]

To start let's assume a logistic model, \[
p(t_{\mathrm{forfeit}} \mid \lambda_{\mathrm{difficulty}, s},
                            \lambda_{\mathrm{skill}, e},
                            \kappa_{e}, \beta_{e})
= \
\mathrm{logistic}( \beta_{e} \cdot (
                   (   \lambda_{\mathrm{difficulty}, s}
                     - \lambda_{\mathrm{skill}, e})
                    - \kappa_{e}     ) ),
\] where \(\kappa\) quantifies the threshold contrast where an entrant
achieves a forfeit probability of \(\frac{1}{2}\) and \(\beta\)
quantifies how sensitive the forfeit probability is to the difference
around this threshold. In order to ensure that a larger contrast always
results in a higher forfeit we'll need to assume that \(\beta\) is
limited to only positive values.

Beyond this functional form it's not straightforward to elicit domain
expertise about reasonable values for \(\kappa\) and \(\beta\). Here
let's just take a prior model that constraint \(\kappa\) and \(\beta\)
below five in order to avoid saturating the outputs of the logistic
function too quickly.

Lastly once we explicitly model forfeits we are in a position to predict
forfeits. This in turn provides new opportunities for retrodictive check
summary statistics. In particular here we will consider the total number
of forfeits in each race.

\begin{codelisting}

\caption{\texttt{model3.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who forfeit and did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting forfeited entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}

  \CommentTok{// Forfeited entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ gamma;                       }\CommentTok{// Log baseline finish time (log seconds)}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ difficulties; }\CommentTok{// Seed difficulties}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ skills;    }\CommentTok{// Entrant skills}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi;                }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  gamma \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);    }\CommentTok{// log(1800 s) \textless{} gamma \textless{} log(5400 s)}
\NormalTok{  difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.299}\NormalTok{); }\CommentTok{// {-}log(2) \textless{}\textasciitilde{} difficulties \textless{}\textasciitilde{} +log(2)}
\NormalTok{  skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.299}\NormalTok{);       }\CommentTok{// {-}log(2) \textless{}\textasciitilde{}    skills    \textless{}\textasciitilde{} +log(2)}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);          }\CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{);        }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);         }\CommentTok{// 0 \textless{}\textasciitilde{} betas \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_N\_entrants\_dnf\_pred = rep\_array(}\DecValTok{0}\NormalTok{, N\_races);}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who forfeited}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}

    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

      \CommentTok{// Finish time prediction conditioned on not forfeiting}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}

      \CommentTok{// Forfeit prediction}
\NormalTok{      race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \CommentTok{// Forfeit prediction}
\NormalTok{        race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model3.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The diagnostics continue to complain about strong auto-correlations but
no new problems have arisen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics3 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples3 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}skills\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{summarize\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands gamma, skills[1], skills[3], skills[4], skills[5],
skills[12], skills[16], skills[17], skills[18], skills[22], skills[24],
skills[26], skills[29], skills[30], skills[34], skills[36], skills[43],
skills[44], skills[45], skills[48], skills[55], skills[57], skills[58],
skills[59], skills[60], skills[64], skills[65], skills[70], skills[71],
skills[72], skills[73], skills[78], skills[81], skills[88], skills[90],
skills[91], skills[93], skills[94], skills[95], skills[96],
skills[100], skills[105], skills[107], kappas[44], kappas[94],
kappas[98] triggered diagnostic warnings.

The expectands gamma, skills[1], skills[3], skills[4], skills[5],
skills[12], skills[16], skills[17], skills[18], skills[22], skills[24],
skills[26], skills[29], skills[30], skills[34], skills[36], skills[43],
skills[44], skills[45], skills[48], skills[55], skills[57], skills[58],
skills[59], skills[60], skills[64], skills[65], skills[70], skills[71],
skills[72], skills[73], skills[78], skills[81], skills[88], skills[90],
skills[91], skills[93], skills[94], skills[95], skills[96],
skills[100], skills[105], skills[107], kappas[44] triggered hat{ESS}
warnings.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

Perhaps surprisingly the worst auto-correlations continue to slightly
improve.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{min\_ess\_hats }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_ess\_hats}\NormalTok{(base\_samples)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(min\_ess\_hats, }\DecValTok{0}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                    \AttributeTok{xlab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Smallest Empirical Effective Sample Size}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
                                \StringTok{"Across All Markov Chains For Each Expectand"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, values): 446 values (86.6%)
fell below the binning.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\DecValTok{100}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lty=}\DecValTok{3}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-33-1.pdf}

The retrodictive agreement between the observed and posterior predictive
finish time histograms continues.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples3, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-34-1.pdf}

Now we can also consider the number of forfeits in each race.
Fortunately the behavior of this statistic is also reasonably
consistent.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_N\_entrants\_dnf\_pred[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"N\_dnf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-35-1.pdf}

To make the comparison more clear we can always visualize the residuals
and then compare to zero.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_N\_entrants\_dnf\_pred[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                                     \AttributeTok{residual=}\ConstantTok{TRUE}\NormalTok{,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"N\_dnf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-36-1.pdf}

Finally the finish time histograms separated by selected races and
entrants also show no signs of retrodictive tension.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 99 predictive values (0.2%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 152 predictive values (0.2%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 3 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-37-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 6 predictive values (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 1 predictive value (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 10 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-38-1.pdf}

Without any concerns about our modeling assumptions we can move on to
examining the resulting posterior inferences. Inferences for the
existing parameters are at least superficially similar to those from the
second model; we'll make a more direct comparison in
\hyperref[sec:inf-comp]{Section 4.5}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"gamma"}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"psi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-39-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Difficulty"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-40-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Skill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-41-1.pdf}

More interesting here are the posterior inferences for the new,
forfeit-related parameters. Overall the uncertainties are relatively
large but we can pick out a few exceptional behaviors

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Forfeit Threshold"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-42-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}betas[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Forfeit Scale"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-43-1.pdf}

For example posterior inferences of the forfeit thresholds for entrants
37 and 38 both concentrate on negative values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{37}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{38}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-44-1.pdf}

Both of these entrants forfeited every race they entered.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summarize\_entrant }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
\NormalTok{  N }\OtherTok{\textless{}{-}}\NormalTok{ N\_entrant\_f\_races[e] }\SpecialCharTok{+}\NormalTok{ N\_entrant\_dnf\_races[e]}
\NormalTok{  Nf }\OtherTok{\textless{}{-}}\NormalTok{ N\_entrant\_f\_races[e]}
\NormalTok{  Ndnf }\OtherTok{\textless{}{-}}\NormalTok{ N\_entrant\_dnf\_races[e]}

  \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Entrant \%i}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, e))}
  \ControlFlowTok{if}\NormalTok{ (N }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i total entrances}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, N))}
  \ControlFlowTok{else}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i total entrance}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, N))}

  \ControlFlowTok{if}\NormalTok{ (Nf }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i finishes (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Nf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Nf }\SpecialCharTok{/}\NormalTok{ N))}
  \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (Nf }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i finish (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Nf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Nf }\SpecialCharTok{/}\NormalTok{ N))}

  \ControlFlowTok{if}\NormalTok{ (Ndnf }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i forfeits (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Ndnf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Ndnf }\SpecialCharTok{/}\NormalTok{ N))}
  \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (Ndnf }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i forfeit (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Ndnf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Ndnf }\SpecialCharTok{/}\NormalTok{ N))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(}\DecValTok{37}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 37
  2 total entrances
  2 forfeits (100.0%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(}\DecValTok{38}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 38
  2 total entrances
  2 forfeits (100.0%)
\end{verbatim}

On the other hand posterior inferences of the forfeit threshold for
entrant 65 concentrates on positive values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-47-1.pdf}

This entrant forfeited only once out of 64 total entrances.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 65
  64 total entrances
  63 finishes (98.4%)
  1 forfeit (1.6%)
\end{verbatim}

Moreover that forfeit occurred for a particularly difficult seed,
pushing the consistent forfeit threshold behaviors to larger values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
  \ControlFlowTok{if}\NormalTok{ (data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf[r] }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\ControlFlowTok{next}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_dnf\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_dnf\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs[idxs])}
\NormalTok{    dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(dnf\_races, r)}
\NormalTok{\}}

\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, dnf\_races[}\DecValTok{1}\NormalTok{], }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{40}\NormalTok{, }\AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Seed Difficulty"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{, dnf\_races[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-49-1.pdf}

Finally the posterior inferences of the forfeit threshold for entrant 44
mostly concentrates on values between \(0\) and \(1\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{44}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-50-1.pdf}

While entrant 44 finishes most of their entrances forfeits are not
uncommon.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 44
  71 total entrances
  56 finishes (78.9%)
  15 forfeits (21.1%)
\end{verbatim}

This higher propensity to forfeit suppresses larger values of the
forfeit threshold.

Overall our posterior inferences for the forfeit behavior are
reasonable, but the relative scarcity of forfeits prevents us from
resolving that behavior with too much precision.

\subsection{Model 4}\label{model-4}

A natural extension of the current model is to couple the behavior
across seeds and entrants, allowing data to be shared and reducing
inferential uncertainties especially for races and entrants with few
entrances to inform them directly. In particular if our domain expertise
about these behaviors is exchangeable then we can couple them together
with hierarchical models. As a side benefit we can also use the inferred
hierarchical population behavior to make inferences and predictions
about new, hypothetical seeds and entrants.

Because the MapRando version distinguishes some seeds from each other,
however, not all of the seed difficulties are exchangeable. That said we
don't have any information to discriminate between the seeds
\emph{within} a version, suggesting a conditional exchangeabilty. In
other words we can couple the seed difficulties within each MapRando
version together into separate hierarchical models.

For programmatic convenience we'll just need to convert the version
numbers into sequential indices.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniq\_versions }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(race\_info}\SpecialCharTok{$}\NormalTok{versions)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(uniq\_versions)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{version\_idxs }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{factor}\NormalTok{(race\_info}\SpecialCharTok{$}\NormalTok{versions,}
                                       \AttributeTok{levels=}\NormalTok{uniq\_versions,}
                                       \AttributeTok{labels=}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions))}
\end{Highlighting}
\end{Shaded}

On the other hand we don't have any prior information capable of
discriminating between the entrants, at least not without doing
additional research into their experience with Super Metroid® in general
and MapRando in particular. Consequently all of the entrant behaviors
are exchangeable with each other and can be captured within a single
hierarchy. For simplicity I will couple only the entrant skills
together, leaving the heterogeneous entrant forfeit behaviors
independent of each other.

Because the seed difficulties and entrant skills are modeled with
one-dimensional, and unconstrained, real values we can reach for the
standard normal hierarchical model. The last step we then need in order
to fully define the model is a parameterization of the individual
parameters in each hierarchy. Here I will use a monolithic non-centered
parameterization for all of the hierarchies and hope that the large
number of seeds and entrants results in strong enough regularization to
suppress any problematic degeneracies. In the worst case our
computational diagnostics will indicate if we need to consider more
sophisticated parameterizations.

\begin{codelisting}

\caption{\texttt{model4.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting did not finish entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;   }\CommentTok{// Entrant index}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times; }\CommentTok{// Entrant finish times}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs; }\CommentTok{// Entrant index}

  \CommentTok{// MapRando versioning}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_versions;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_versions\textgreater{} version\_idxs;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ gamma;                       }\CommentTok{// Log baseline finish time (log seconds)}

  \DataTypeTok{vector}\NormalTok{[N\_races] eta\_difficulties; }\CommentTok{// Non{-}centered seed difficulties}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] tau\_difficulties; }\CommentTok{// Seed difficulty population scale}

  \DataTypeTok{vector}\NormalTok{[N\_entrants] eta\_skills;    }\CommentTok{// Non{-}centered entrant skills}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} tau\_skills;         }\CommentTok{// Entrant skill population scale}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi;                }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \CommentTok{// Derive centered race difficulties and entrant skills}
  \DataTypeTok{vector}\NormalTok{[N\_races] difficulties}
\NormalTok{    = tau\_difficulties[version\_idxs] .* eta\_difficulties;}
  \DataTypeTok{vector}\NormalTok{[N\_entrants] skills}
\NormalTok{    = tau\_skills * eta\_skills;}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  gamma \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{); }\CommentTok{// log(1800 s) \textless{} gamma \textless{} log(5400 s)}
\NormalTok{  eta\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);     }\CommentTok{// Non{-}centered individual model}
\NormalTok{  tau\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.270}\NormalTok{); }\CommentTok{// 0 \textless{}\textasciitilde{} tau\_difficulties \textless{}\textasciitilde{} log(2)}
\NormalTok{  eta\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);           }\CommentTok{// Non{-}centered individual model}
\NormalTok{  tau\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.270}\NormalTok{);       }\CommentTok{// 0 \textless{}\textasciitilde{}    tau\_skills    \textless{}\textasciitilde{} log(2)}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);       }\CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{);     }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);      }\CommentTok{// 0 \textless{}\textasciitilde{} betas \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_N\_entrants\_dnf\_pred = rep\_array(}\DecValTok{0}\NormalTok{, N\_races);}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}

    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

      \CommentTok{// Finish time prediction conditioned on not forfeiting}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}

      \CommentTok{// Forfeit prediction}
\NormalTok{      race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \CommentTok{// Forfeit prediction}
\NormalTok{        race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model4.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Fortunately we don't see any of the tell-tale signs of problematic
hierarchical geometries, such as divergences and E-FMI warnings.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}eta\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}eta\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{summarize\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands gamma, tau_difficulties[6], eta_skills[4],
eta_skills[5], eta_skills[12], eta_skills[16], eta_skills[17],
eta_skills[18], eta_skills[24], eta_skills[29], eta_skills[44],
eta_skills[45], eta_skills[58], eta_skills[60], eta_skills[65],
eta_skills[70], eta_skills[90], eta_skills[91], eta_skills[93],
eta_skills[94], eta_skills[95], eta_skills[96], eta_skills[100],
eta_skills[105], kappas[44], kappas[86], kappas[94], kappas[98]
triggered diagnostic warnings.

The expectands gamma, tau_difficulties[6], eta_skills[4],
eta_skills[5], eta_skills[12], eta_skills[16], eta_skills[17],
eta_skills[18], eta_skills[24], eta_skills[29], eta_skills[44],
eta_skills[45], eta_skills[58], eta_skills[60], eta_skills[65],
eta_skills[70], eta_skills[90], eta_skills[91], eta_skills[93],
eta_skills[94], eta_skills[95], eta_skills[96], eta_skills[100],
eta_skills[105], kappas[44] triggered hat{ESS} warnings.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

In fact the empirical effective sample sizes are consistently larger,
and hence the auto-correlations consistently weaker, than before! This
suggests that the hierarchical coupling is indeed reducing the posterior
uncertainties and improving the overall posterior geometry.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}difficulties\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{min\_ess\_hats3 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_ess\_hats}\NormalTok{(base\_samples)}

\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}difficulties\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{min\_ess\_hats4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_ess\_hats}\NormalTok{(base\_samples)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(min\_ess\_hats3, min\_ess\_hats4, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{,}
     \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Smallest Empirical Effective Sample Size}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
                 \StringTok{"Across All Markov Chains For Each Expectand"}\NormalTok{),}
     \AttributeTok{xlab=}\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1100}\NormalTok{),}
     \AttributeTok{ylab=}\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1100}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a=}\DecValTok{0}\NormalTok{, }\AttributeTok{b=}\DecValTok{1}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lty=}\DecValTok{3}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-55-1.pdf}

A review of our visual retrodictive checks doesn't show any indications
that the introduction of the hierarchical coupling compromised the
adequacy of our modeling assumptions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples4, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-56-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_N\_entrants\_dnf\_pred[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                                     \AttributeTok{residual=}\ConstantTok{TRUE}\NormalTok{,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"N\_dnf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-57-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs, }\ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 79 predictive values (0.2%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 87 predictive values (0.1%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 5 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-58-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs, }\ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 5 predictive values (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 2 predictive values (0.0%) fell below the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 9 predictive values (0.0%) fell below the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-59-1.pdf}

Now we can explore the posterior inferences for not just the individual
behaviors but also the hierarchical populations from which those
behaviors are, at least mathematically, drawn.

Each MapRando version defines a separate hierarchical population and,
unsurprisingly, the inferred population behavior is most precise for the
later versions that have been played the most.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions) \{}
  \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{  races }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{version\_idxs }\SpecialCharTok{==}\NormalTok{ v)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(races, }\ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                       \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                       \AttributeTok{xticklabs=}\NormalTok{races,}
                                       \AttributeTok{ylab=}\StringTok{"Difficulty"}\NormalTok{)}

\NormalTok{  name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}tau\_difficulties[\textquotesingle{}}\NormalTok{, v, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{30}\NormalTok{, }\AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{1.1}\NormalTok{),}
                                  \AttributeTok{display\_name=}\StringTok{"tau\_difficulties"}\NormalTok{,}
                                  \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Version"}\NormalTok{, uniq\_versions[v]))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-1.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-2.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-3.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-4.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-5.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-6.pdf}

Subject to the posterior uncertainties all of the version population
behaviors are consistent with each other. For example both versions 112
and 113 strongly suppress seed difficulty magnitudes above \[
2 \tau_{\mathrm{difficulty}} \approx 0.4,
\] implying range of proportional changes to the baseline finish time
between \[
\exp(-0.4) \approx 0.67
\] and \[
\exp(+0.4) \approx 1.49.
\]

Interestingly the entrant skills exhibit similar regularization, with
the population scale concentrating just under \(0.3\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Skill"}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[}\StringTok{\textquotesingle{}tau\_skills\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"tau\_skills"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-1.pdf}

\subsection{Inferential Comparison}\label{sec:inf-comp}

Before applying our posterior inferences to make useful statements about
the entrants and their behavior in future races let's pause and examine
the impact our model development has had on our posterior inferences.

\subsubsection{Log Baseline}\label{log-baseline}

To start let's look at the parameter \(\gamma\) which, once
exponentiated, sets the baseline finish time.

Interestingly changing the observational model doesn't seem to have
strongly impacted \(\gamma\), at least within the resolution of our
Markov chain Monte Carlo estimators.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{8.45}\NormalTok{, }\FloatTok{8.8}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"gamma"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.525}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{8.45}\NormalTok{, }\FloatTok{8.8}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.675}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-62-1.pdf}

On the other hand incorporating forfeits results in a substantial shift
of the entire marginal posterior distribution up to larger values,
implying longer baseline finish times. This makes sense because without
accounting for forfeits the observed finish times are biased towards
more optimistic outcomes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{8.45}\NormalTok{, }\FloatTok{8.8}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"gamma"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.525}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{8.45}\NormalTok{, }\FloatTok{8.8}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-63-1.pdf}

The introduction of the seed difficulty and entrant skill hierarchies
has no impact on smaller values of \(\gamma\) but it does suppress
larger values, giving a narrower marginal posterior distribution. This
is just a manifestation of the smaller uncertainties that appropriately
coupling the individuals behaviors together can give.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{8.45}\NormalTok{, }\FloatTok{8.8}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{15}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"gamma"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.55}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{8.45}\NormalTok{, }\FloatTok{8.8}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-64-1.pdf}

\subsubsection{Entrant 29 Skill}\label{entrant-29-skill}

Now let's dig into posterior inferences for some entrants with
particularly extreme observed behaviors that will hopefully emphasize
the impact of our model improvements.

For example the record of entrant 29 features lots of entrances and only
a single forfeit. Consequently we might naively expect the introduction
of forfeits and the entrant skill hierarchy to have less impact on
inferences for the skill parameter of entrant 29.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{29}
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 29
  68 total entrances
  67 finishes (98.5%)
  1 forfeit (1.5%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{xname }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{} Skill\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Transitioning from a gamma to inverse gamma observational model seems to
yield a very slight shift of the marginal skill posterior distribution
to smaller values. On the other hand because this shift is largely
enveloped by the Markov chain Monte Carlo errors it could also just be a
computational artifact.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.49}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.355}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-67-1.pdf}

Interestingly the introduction of forfeits into the model has a much
stronger impact on the marginal skill posterior distribution, shifting
it up to larger values. Even though entrant 29 rarely forfeited the
ignorance of forfeits can allow data from other entrants to bias
inferences for common parameters like \(\gamma\), which then bias
inferences for all entrant skills.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.355}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-68-1.pdf}

The introduction of the skill hierarchy has a similar, albeit weaker,
influence on the entrant 29 skill parameter as it did on \(\gamma\).
Larger values are suppressed, narrowing the marginal posterior
distribution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{14}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.49}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.36}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-69-1.pdf}

\subsubsection{Entrant 44 Skill}\label{entrant-44-skill}

Let's contrast these changes with those for the skill parameter of
entrant 44, who also entered into many races but forfeited at a much
higher rate than entrant 29.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{44}
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 44
  71 total entrances
  56 finishes (78.9%)
  15 forfeits (21.1%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{xname }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{} Skill\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Again the tweak of the observational model has a negligible impact on
the marginal posterior inferences.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.12}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.24}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-72-1.pdf}

Somewhat surprisingly incorporating forfeits shifts the entrant 44 skill
parameter to larger values!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.12}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.255}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-73-1.pdf}

This suggests that entrant 44 forfeiting for only particularly difficult
races. Indeed examining the seed difficulty inferences it appears that
entrant 44 has largely forfeited only when confronted with difficult
seeds.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs[idxs])}
\NormalTok{    f\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(f\_races, r)}
\NormalTok{\}}

\NormalTok{dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
  \ControlFlowTok{if}\NormalTok{ (data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf[r] }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\ControlFlowTok{next}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_dnf\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_dnf\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs[idxs])}
\NormalTok{    dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(dnf\_races, r)}
\NormalTok{\}}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(f\_races, }\ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{xticklabs=}\NormalTok{f\_races,}
                                     \AttributeTok{ylab=}\StringTok{"Difficulty"}\NormalTok{,}
                                     \AttributeTok{display\_ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                     \AttributeTok{main=}\StringTok{"Entrant 44 Finished"}\NormalTok{)}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(dnf\_races, }\ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{xticklabs=}\NormalTok{dnf\_races,}
                                     \AttributeTok{ylab=}\StringTok{"Difficulty"}\NormalTok{,}
                                     \AttributeTok{display\_ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.6}\NormalTok{),}
                                     \AttributeTok{main=}\StringTok{"Entrant 44 Forfeited"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-74-1.pdf}

Because the entrant 44 skill parameter concentrates on smaller values
than the entrant 29 skill parameter the influence of the hierarchical
coupling isn't as pronounced. Here only a small slice of larger values
are suppressed and the marginal posterior distribution tightens only
slightly.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{13}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.12}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.4}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.26}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-75-1.pdf}

\subsubsection{Entrant 83 Skill}\label{entrant-83-skill}

Lastly let's take a look at an entrant with only a few race entrances.
In particular entrant 83 has only five entrances and almost half of them
are forfeits.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{83}
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 83
  5 total entrances
  3 finishes (60.0%)
  2 forfeits (40.0%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{xname }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{} Skill\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once again the transition from gamma to inverse gamma observational
models has little impact on the marginal skill inferences.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.075}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-78-1.pdf}

Incorporating forfeits pushes the skill marginal posterior distribution
to larger values, but only slightly.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-79-1.pdf}

It's hard to say if the hierarchical coupling has any substantial
impact. There is perhaps a very weak suppression of more negative skill
values, but that trend is also within the span of the Markov chain Monte
Carlo estimator errors.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{5.5}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.6}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-80-1.pdf}

In hindsight we shouldn't expect any substantial impact from the
introduction of the hierarchical modeling components given that the
initial posterior inferences for the entrant 83 skill parameter already
concentrated with the inferred span of the hierarchical population
model.

\subsection{Possible Model Expansions}\label{possible-model-expansions}

At this point our model appears to be adequate, at least within the
scope of the summary statistics that we considered. In particular
because we only spot checked the retrodictive behavior for a few
individual races and entrants there is plenty of room for subtle model
inadequacies to hide. Moreover the available domain expertise suggests
plenty of possible model improvements that we could investigate more
carefully if we had the time, need, or both.

Attempting to implement any of these model expansions would be a useful
exercise for any enterprising readers.

\subsubsection{Idiosyncratic Entrants}\label{idiosyncratic-entrants}

Given that we have already argued that our domain expertise about the
entrant behaviors is exchangeable there is nothing preventing us from
hierarchically modeling the variation in not only entrant skill but also
entrant forfeit behaviors.

If entrant skill, forfeit threshold, and forfeit scale all varied
independently then implementing this model would be mostly
straightforward, with some possible challenges in accommodating the
positivity constraint on the forfeit scale. There's no immediate reason,
however, why the heterogeneity in these parameters wouldn't be coupled
together. For example entrants with higher skills might also tend to
have higher forfeit thresholds and vice versa. In this case we would
need to consider a multivariate hierarchical population model.

This is the inevitable challenge with hierarchical modeling in practice.
Once we identify which behaviors are heterogeneous and exchangeable we
still need to determine \emph{how} those behaviors could vary.

\subsubsection{Transcending Normal Population
Models}\label{transcending-normal-population-models}

Speaking of hierarchies, we are in a somewhat privileged position with
the large number of entrants and seeds in our data set. This abundance
of contexts might allow us to resolve more sophisticated hierarchical
population behavior beyond the normal population model that we have
assumed. For example we could consider a Student's \(t\) population
model where we have to infer not only the breadth of the population but
also the precise shape of the population tails.

This more flexible hierarchical population model would allow our
inferences to better accommodate sparsity, strongly regularizing most of
the seed difficulties or entrant skills towards zero while allowing the
more extreme behaviors to be more weakly regularized.

\subsubsection{Self-Improvement}\label{self-improvement}

When exploring the time-dependence of the seed difficulties we briefly
considered time-dependent entrant skills before accepting the evolving
MapRando version as the most likely explanation. That said there's no
reason why we couldn't expand our model to allow for time-dependent
entrant skills, if only to see if we could resolve any substantial
dependencies with the data we have collected.

The main challenge with implementing time-dependent skills is
determining how exactly to model how entrants improve and hence what
kinds of time-dependencies we should prioritize. For example if learning
scales with the number of MapRando games played, and entrant interest in
the game is not uniform in time, then modeling skill as a function of
race date-time might not be the most best path. Instead it might be more
productive to allow entrant skills to depend on cumulative participation
or even something else entirely.

We still then have to determine the possible functional relationships
between skill and the appropriate evolution metric. We could, for
instance, simply assume a linear relationship for simplicity or consider
more sophisticated relationships that allow for more complicated
behaviors such as saturation.

\subsubsection{Variable Variability}\label{variable-variability}

Throughout our model development have assumed a common \(\psi\) across
all races, even as the randomization seeds change. That said sometimes
the MapRando randomization logic results in particularly ambiguous
progression paths; entrants taking the correct path first will tend to
finish especially fast while those who explore the incorrect paths will
tend to finish later, resulting in especially large variability. This is
especially true if a seed allows for unintended sequence breaks of which
only the more skilled entrants can take advantage. On the other hand
some seeds result in progression paths that are easier to predict which
narrows the range of possible finish times.

One way to account for this heterogeneity is to allow \(\psi\) to vary
across seeds. We could even model the \(\psi\) parameters hierarchically
to help regularize inferences for races with only a few entrants.

Before expanding the model, however, we would first want to see if we
can identify any consequences of this behavior in new posterior
retrodictive checks. For example we could look at the finish time
histograms for more races to see if the observed behavior is wider or
narrow than the posterior predictive behavior. We could also try to
engineer summary statistics that are directly sensitive to the
variability, such as the ratio of the empirical variance to the squared
empirical mean within each race and even statistics that are sensitive
to heterogeneity in those individual race statistics.

At the same time entrants who are more experienced with MapRando games,
especially the underlying logic of the map randomization, can often
identify the correct progression paths quickly and avoid wasting time
exploring dead ends. This suggests that \(\psi\) could also vary across
entrants. The study of this heterogeneity would proceed similarly to the
above study of seed heterogeneity, only separating the summary
statistics by individual entrants instead of individual races.

\section{Actionable Insights}\label{actionable-insights}

Although it's easy to become distracted by all of the directions we can
take our last model we don't want to forget all of the powerful things
that we can already do with it. In this section we'll apply our
posterior inferences to a few applications that might arise in actual
practice.

\subsection{Ranking Entrants}\label{ranking-entrants}

A common objective of races is to construct leader boards where entrants
are ranked in order of their performance. For example
\texttt{https://racetime.gg/smr} uses a heuristic, iterative system to
assign points to entrants based on their performance in each race and
then uses those points to determine a dynamic
\href{https://racetime.gg/smr/leaderboards}{leader board}. The top nine
entrants as of August 3rd, 2024 are shown in
Table~\ref{tbl-leader-board}.

\begin{longtable}[]{@{}llllllllll@{}}
\caption{The website \texttt{https://racetime.gg/smr} ranks entrants
based on points earned during each
race.}\label{tbl-leader-board}\tabularnewline
\toprule\noalign{}
Rank & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Rank & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Entrant Index & 70 & 105 & 29 & 100 & 18 & 91 & 60 & 65 & 4 \\
\end{longtable}

Our posterior distribution can also be used to rank the entrants by
their inferred skills.

Mathematically any configuration of entrant skills \[
( \lambda_{\mathrm{skill}, 1}, \ldots,
  \lambda_{\mathrm{skill}, e}, \ldots,
  \lambda_{\mathrm{skill}, N_{\mathrm{entrants}}} )
\in \left( \Lambda_{\mathrm{skill}} \right)^{N_{\mathrm{entrants}}}
\] implies a unique ranking \[
(r_{1}, \ldots, r_{e}, \ldots, r_{N_{\mathrm{entrants}}}) \in R
\] where entrants are ordered by their their individual skills, \[
\lambda_{\mathrm{skill}, r_{1}} > \ldots >
\lambda_{\mathrm{skill}, r_{e}} > \ldots >
\lambda_{\mathrm{skill}, r_{N_{\mathrm{entrants}}}}.
\] This in fact defines a bijective function from the space of entrant
skills to the space \(R\) of the \(N_{\mathrm{entrants}}!\) possible
orderings of the \(N_{\mathrm{entrants}}\) entrants, \[
o : \left( \Lambda_{\mathrm{skill}} \right)^{N_{\mathrm{entrants}}}
    \rightarrow R.
\]

Pushing forward our posterior distribution along this function gives a
posterior distribution \(o_{*} \pi\) that quantifies our uncertainty
about the possible entrant rankings. The only challenge is that the
space of ranking \(R\) is massive and difficult to navigate. In
particular it's not immediately clear how we can construct practical
point summaries of this rank posterior distribution for applications
like leader boards.

For example intuitively we might be interested in point estimates that
quantify the centrality of the rank posterior distribution in some way.
Because the space of rankings is discrete each rank will in general be
allocated non-zero probability and we might consider a modal ranking, \[
r^{*} = \underset{r \in R}{\mathrm{argmax}} \; o_{*} \pi( \{ r \} ).
\] Unfortunately even if a unique mode exists actually finding it will
typically be intractable. Not only can we not compute the atomic
allocations \(o_{*} \pi( \{ r \} )\) in closed form but also
exhaustively searching through all \(N_{\mathrm{entrants}}!\) elements
will almost always be too expensive and we have no gradient information
to guide a more efficient search.

In analogy to a posterior mean we might consider a distance function
\(d : R \times R \rightarrow \mathbb{R}^{+}\) and then define a point
summary that minimizes the expected distance, \[
\mu_{R}
=
\underset{r \in R}{\mathrm{argmin}} \; \mathbb{E}_{o_{*} \pi}[ d( \cdot, r) ].
\] Conveniently there are a variety of useful distance functions on
\(R\) that we could use here. and the expectation values can be readily
estimated with Markov chain Monte Carlo. The minimization over all
possible candidate rankings \(r \in R\), however, suffers from the same
problems as above.

Because of these computational issues we will usually need to appeal to
more heuristic methods in practice. For instance we can always rank the
entrants by the posterior expectation values of their individual skills.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expected\_skill }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(samples4[[}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)]])[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}

\NormalTok{expected\_skills }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                          \ControlFlowTok{function}\NormalTok{(e) }\FunctionTok{expected\_skill}\NormalTok{(e))}

\NormalTok{ranked\_entrants }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(expected\_skills, }\AttributeTok{index.return=}\ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{ix}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{) \{}
  \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Rank \%i: Entrant \%i}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
\NormalTok{              r, ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ r]))}
  \ControlFlowTok{if}\NormalTok{ (r }\SpecialCharTok{==} \DecValTok{9}\NormalTok{) }\FunctionTok{cat}\NormalTok{(}\StringTok{"..."}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rank 1: Entrant 70
Rank 2: Entrant 29
Rank 3: Entrant 18
Rank 4: Entrant 105
Rank 5: Entrant 100
Rank 6: Entrant 91
Rank 7: Entrant 60
Rank 8: Entrant 65
Rank 9: Entrant 24
...
\end{verbatim}

Interestingly the top eight entrants in this heuristic ranking are the
same as the top eight entrants in the official
\texttt{https://racetime.gg/smr} leader boards. That said the ordering
of positions two through five are different.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rank }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}
\NormalTok{post\_mean\_ranking }\OtherTok{\textless{}{-}} \FunctionTok{rev}\NormalTok{(}\FunctionTok{tail}\NormalTok{(ranked\_entrants, }\DecValTok{9}\NormalTok{))}
\NormalTok{racetime\_ranking }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{70}\NormalTok{, }\DecValTok{105}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{91}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{4}\NormalTok{)}

\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(rank, post\_mean\_ranking, racetime\_ranking)}
\FunctionTok{names}\NormalTok{(df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Rank"}\NormalTok{, }\StringTok{"Posterior Mean Ranking"}\NormalTok{, }\StringTok{"racetime.gg Ranking"}\NormalTok{)}

\FunctionTok{print}\NormalTok{(df, }\AttributeTok{row.names=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Rank Posterior Mean Ranking racetime.gg Ranking
    1                     70                  70
    2                     29                 105
    3                     18                  29
    4                    105                 100
    5                    100                  18
    6                     91                  91
    7                     60                  60
    8                     65                  65
    9                     24                   4
\end{verbatim}

Inconsistent rankings is not at all surprising given our posterior
uncertainties. For example even though entrant 70 exhibits a higher
expected skill than entrant 29 our inferential uncertainties are not
inconsistent with the exact skill of entrant 29 actually surpassing the
exact skill of entrant 70.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{3}\NormalTok{]}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.65}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{15}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Skill"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.36}\NormalTok{, }\FloatTok{11.5}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Rank 3}\SpecialCharTok{\textbackslash{}n}\StringTok{Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{]}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.65}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.415}\NormalTok{, }\FloatTok{14.25}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Rank 2}\SpecialCharTok{\textbackslash{}n}\StringTok{Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid)}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.65}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.485}\NormalTok{, }\FloatTok{11.5}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Rank 1}\SpecialCharTok{\textbackslash{}n}\StringTok{Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-83-1.pdf}

If we want to compare only two entrants at a time then instead of
comparing their expected skills we can compute the posterior probability
that one skill surpasses the other. In particular this latter comparison
accounts for inferential coupling between the two skill parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{skill\_comp }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(s1, s2) \{}
\NormalTok{  s1 }\SpecialCharTok{\textgreater{}}\NormalTok{ s2}
\NormalTok{\}}

\NormalTok{e1 }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}
\NormalTok{e2 }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{]}
\NormalTok{var\_repl }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}s1\textquotesingle{}} \OtherTok{=} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e1,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{),}
                 \StringTok{\textquotesingle{}s2\textquotesingle{}} \OtherTok{=} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e2,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}

\NormalTok{derived\_samples }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{eval\_expectand\_pushforward}\NormalTok{(samples4,}
                                  \ControlFlowTok{function}\NormalTok{(s1, s2) }\FunctionTok{as.numeric}\NormalTok{(s1 }\SpecialCharTok{\textgreater{}}\NormalTok{ s2),}
\NormalTok{                                  var\_repl)}

\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(derived\_samples)[}\DecValTok{1}\NormalTok{]}

\NormalTok{format\_string }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"Probability that entrant \%i skill is "}\NormalTok{,}
                        \StringTok{"larger than entrant \%i skill = \%.3f."}\NormalTok{)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(format\_string, e1, e2, p))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Probability that entrant 70 skill is larger than entrant 29 skill = 0.941.
\end{verbatim}

These relative comparisons can also be used to construct another
heuristic ranking. For example we could compute the probability that the
skill of each entrant is larger than all other entrants and assign first
place based on the highest probability. Then we could compute the
probability that the skill of each remaining entrant is larger than all
of the other remaining entrants and assign second place based on the
highest of these probabilities. Finally we could fill out all of the
rankings by iterating this procedure until only one entrant is left to
occupy last place.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{skill\_comp }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(active\_skill, ...) \{}
\NormalTok{  other\_skills }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(...)}
\NormalTok{  pairwise\_comps }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(other\_skills,}
                           \ControlFlowTok{function}\NormalTok{(other\_skill)}
\NormalTok{                           active\_skill }\SpecialCharTok{\textgreater{}}\NormalTok{ other\_skill)}
  \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{Reduce}\NormalTok{(}\StringTok{"\&"}\NormalTok{, pairwise\_comps))}
\NormalTok{\}}

\NormalTok{best\_entrant }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(entrant\_idxs) \{}
\NormalTok{  probs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

  \ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in}\NormalTok{ entrant\_idxs) \{}
\NormalTok{    other\_entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ entrant\_idxs[}\SpecialCharTok{{-}}\FunctionTok{which}\NormalTok{(entrant\_idxs }\SpecialCharTok{==}\NormalTok{ e)]}
\NormalTok{    var\_repl }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}active\_skill\textquotesingle{}} \OtherTok{=} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{),}
                     \StringTok{\textquotesingle{}...\textquotesingle{}} \OtherTok{=} \FunctionTok{sapply}\NormalTok{(other\_entrant\_idxs,}
                                    \ControlFlowTok{function}\NormalTok{(oe)}
                                    \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, oe,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)))}

\NormalTok{    comps }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{eval\_expectand\_pushforward}\NormalTok{(samples4,}
\NormalTok{                                             skill\_comp,}
\NormalTok{                                             var\_repl)}

\NormalTok{    probs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(probs, util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(comps)[}\DecValTok{1}\NormalTok{])}
\NormalTok{  \}}

\NormalTok{  entrant\_idxs[}\FunctionTok{which}\NormalTok{(probs }\SpecialCharTok{==} \FunctionTok{max}\NormalTok{(probs))]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_idxs }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants}
\NormalTok{e\_first }\OtherTok{\textless{}{-}} \FunctionTok{best\_entrant}\NormalTok{(entrant\_idxs)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"First Place: Entrant \%i"}\NormalTok{, e\_first))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
First Place: Entrant 70
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ entrant\_idxs[}\SpecialCharTok{{-}}\FunctionTok{which}\NormalTok{(entrant\_idxs }\SpecialCharTok{==}\NormalTok{ e\_first)]}
\NormalTok{e\_second }\OtherTok{\textless{}{-}} \FunctionTok{best\_entrant}\NormalTok{(entrant\_idxs)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Second Place: Entrant \%i"}\NormalTok{, e\_second))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Second Place: Entrant 29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ entrant\_idxs[}\SpecialCharTok{{-}}\FunctionTok{which}\NormalTok{(entrant\_idxs }\SpecialCharTok{==}\NormalTok{ e\_second)]}
\NormalTok{e\_third }\OtherTok{\textless{}{-}} \FunctionTok{best\_entrant}\NormalTok{(entrant\_idxs)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Third Place: Entrant \%i"}\NormalTok{, e\_third))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Third Place: Entrant 18
\end{verbatim}

Interestingly this give the same top three as the ranking of entrants by
their posterior expected skills. In general, however, this will not
always be the case.

The practical limitations of this approach is that it requires
estimating a lot of expectation values. Moreover if we really wanted to
be careful then we would need to ensure that the Markov chain Monte
Carlo error for each probability estimate is smaller than any of the
differences between the probability estimates so that the resulting
ranks are not corrupted by computational artifacts. In practice this
might require running more Markov chains than usual, longer Markov
chains than usual, or both.

\subsection{Predicting Race Outcomes}\label{predicting-race-outcomes}

Another common application is to make predictions about the outcomes of
future races, or even hypothetical races that might never occur. We can
use our posterior inferences for the observed seed and entrants to
immediately inform predictions about how existing entrants would fare if
they were able to play previous seeds again. In order to make
predictions about the performance of entirely new entrants or new seeds
we will need to take advantage of the hierarchical population models.

Let's rerun our last, hierarchical model only with a new
\texttt{generated\ quantities} block where we simulate posterior
predictive finish statuses and finish times for all existing entrants in
a hypothetical race using a new seed in the latest MapRando version.

\begin{codelisting}

\caption{\texttt{model5.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting did not finish entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;   }\CommentTok{// Entrant index}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times; }\CommentTok{// Entrant finish times}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs; }\CommentTok{// Entrant index}

  \CommentTok{// MapRando versioning}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_versions;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_versions\textgreater{} version\_idxs;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ gamma;                       }\CommentTok{// Log baseline finish time (log seconds)}

  \DataTypeTok{vector}\NormalTok{[N\_races] eta\_difficulties; }\CommentTok{// Non{-}centered seed difficulties}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] tau\_difficulties; }\CommentTok{// Seed difficulty population scale}

  \DataTypeTok{vector}\NormalTok{[N\_entrants] eta\_skills;    }\CommentTok{// Non{-}centered entrant skills}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} tau\_skills;         }\CommentTok{// Entrant skill population scale}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi;                }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \CommentTok{// Derive centered race difficulties and entrant skills}
  \DataTypeTok{vector}\NormalTok{[N\_races] difficulties}
\NormalTok{    = tau\_difficulties[version\_idxs] .* eta\_difficulties;}
  \DataTypeTok{vector}\NormalTok{[N\_entrants] skills}
\NormalTok{    = tau\_skills * eta\_skills;}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  gamma \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{); }\CommentTok{// log(1800 s) \textless{} gamma \textless{} log(5400 s)}
\NormalTok{  eta\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);     }\CommentTok{// Non{-}centered individual model}
\NormalTok{  tau\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.270}\NormalTok{); }\CommentTok{// 0 \textless{}\textasciitilde{} tau\_difficulties \textless{}\textasciitilde{} log(2)}
\NormalTok{  eta\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);           }\CommentTok{// Non{-}centered individual model}
\NormalTok{  tau\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.270}\NormalTok{);       }\CommentTok{// 0 \textless{}\textasciitilde{}    tau\_skills    \textless{}\textasciitilde{} log(2)}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);       }\CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{);     }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);      }\CommentTok{// 0 \textless{}\textasciitilde{} betas \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                                                         race\_f\_start\_idxs[r],}
\NormalTok{                                                         race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = difficulties[r] {-} skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Finish status in a hypothetical new race (0: finish, 1: forfeit)}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} entrant\_statuses\_pred;}

  \CommentTok{// Finish times in a hypothetical new race conditioned on no forfeits}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times\_pred;}
\NormalTok{  \{}
    \CommentTok{// Simulate seed difficulty from latest version}
    \DataTypeTok{real}\NormalTok{ difficulty = normal\_rng(}\DecValTok{0}\NormalTok{, tau\_difficulties[N\_versions]);}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants) \{}
      \DataTypeTok{real}\NormalTok{ delta = difficulty {-} skills[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(gamma + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[n] * (delta {-} kappas[n]);}

\NormalTok{      entrant\_statuses\_pred[n] = bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      entrant\_f\_times\_pred[n] = inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{,}
\NormalTok{                                              mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model5.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Because the \texttt{generated\ quantities} block of Model 5 will consume
pseudo-random number generate state differently than that of Model 4
there is a chance that the realized Markov chains will encounter
different pathologies. Consequently we'll need to double check the
computational diagnostics. Fortunately no new warnings have arisen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}gamma\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}eta\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}eta\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{summarize\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands gamma, eta_skills[4], eta_skills[18], eta_skills[29],
eta_skills[44], eta_skills[58], eta_skills[60], eta_skills[65],
eta_skills[90], eta_skills[91], eta_skills[100], eta_skills[105],
kappas[6], kappas[44], kappas[94], kappas[98] triggered diagnostic
warnings.

The expectands gamma, eta_skills[4], eta_skills[18], eta_skills[29],
eta_skills[44], eta_skills[58], eta_skills[60], eta_skills[65],
eta_skills[90], eta_skills[91], eta_skills[100], eta_skills[105],
kappas[94] triggered hat{ESS} warnings.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{min\_ess\_hats }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_ess\_hats}\NormalTok{(base\_samples)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(min\_ess\_hats, }\DecValTok{0}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                    \AttributeTok{xlab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Smallest Empirical Effective Sample Size}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
                                \StringTok{"Across All Markov Chains For Each Expectand"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, values): 492 values (94.3%)
fell below the binning.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\DecValTok{100}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lty=}\DecValTok{3}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-91-1.pdf}

The uses of these predictions are endless.

\subsubsection{Single Entrant
Predictions}\label{single-entrant-predictions}

For example some entrants not only live-stream their entrances to their
communities but also allow viewers to make non-monetary over/under bets
on their finish time. If we wanted to take these casual activities a bit
too far then we could use our predictions to set a betting line where
both outcomes are equally probable.

Without forfeits the balanced betting line \(t_{\mathrm{gamble}}\) would
be implicitly defined by the condition \[
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, ) = 0.5.
\] In other words \(t_{\mathrm{gamble}}\) would just be given by the
median of the posterior predictive finish time distribution for the
hosting entrant, which we can estimate with Markov chain Monte Carlo.

To be completely fair, however, we need to account for the fact that the
hosting entrant might forfeit. Consequently the relevant condition is
actually \begin{align*}
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, , \mathrm{forfeit} = 0 )
&=
0.5
\\
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, \mid \mathrm{forfeit} = 0 ) \,
\pi( \mathrm{forfeit} = 0 )
&=
0.5
\\
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, \mid \mathrm{forfeit} = 0 ) \,
\left( 1 - \pi( \mathrm{forfeit} = 1 ) \right)
&=
0.5,
\end{align*} or \[
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, \mid \mathrm{forfeit} = 0 )
=
\frac{0.5}{ 1 - \pi( \mathrm{forfeit} = 1 ) }.
\]

Fortunately we can readily compute all of these ingredients using our
\texttt{Stan} output.

To demonstrate let's look at entrant 65. First we can compute the
probability of forfeit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_statuses\_pred[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{p\_dnf }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(samples[[name]])[}\DecValTok{1}\NormalTok{]}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Probability entrant \%i forfeits = \%.3f"}\NormalTok{, e, p\_dnf))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Probability entrant 65 forfeits = 0.018
\end{verbatim}

Because the forfeit probability is so small the balanced probability
allocation needed to define \(t_{\mathrm{gamble}}\) is very close to
\(\frac{1}{2}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_balanced }\OtherTok{\textless{}{-}} \FloatTok{0.5} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_dnf)}
\end{Highlighting}
\end{Shaded}

Averaging the empirical quantiles within each Markov chain provides a
consistent estimate of the exact posterior quantile.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{t\_gamble }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_quantile\_est}\NormalTok{(samples[[name]],}
                                            \FunctionTok{c}\NormalTok{(p\_balanced))}

\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"t\_gamble = \%.3f minutes"}\NormalTok{, t\_gamble }\SpecialCharTok{/} \DecValTok{60}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
t_gamble = 66.923 minutes
\end{verbatim}

\subsubsection{Head-to-Head Predictions}\label{head-to-head-predictions}

We can also predict how two entrants will perform relative to each other
in our hypothetical race. Here we'll consider entrant 29 racing against
entrant 65.

The marginal posterior distribution for the two entrants' skill
parameters overlap quite a bit, but that of entrant 29 does favor larger
values than that of entrant 65.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{29}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.55}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{15}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Skill"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.42}\NormalTok{, }\DecValTok{14}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.55}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\DecValTok{14}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-95-1.pdf}

What really matters for predictive race outcomes, however, are not the
latent skills but rather the predicted finish times. The marginal
posterior predictive distributions for the predicted finish times
overlap even more, indicating a much closer race than we might expect
from the skills alone.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{29}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]] }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{175}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.03}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Skill"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\DecValTok{25}\NormalTok{, }\FloatTok{0.02}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]] }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{175}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\DecValTok{95}\NormalTok{, }\FloatTok{0.02}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-96-1.pdf}

That said the predicted finish times still don't tell the entire story.
To accurately predict a winner we also need to take into account the
possibility that one, or possibly even both, of the entrants forfeits.
Altogether there are five possible outcomes that are relevant to whether
or not entrant 29 beats entrant 65:

\begin{itemize}
\tightlist
\item
  Entrant 29 forfeits and entrant 65 forfeits,
\item
  Entrant 29 forfeits and entrant 65 finishes,
\item
  Entrant 29 finishes and entrant 65 forfeits,
\item
  Entrant 29 finishes and entrant finishes and \(t_{29} < t_{65}\),
\item
  Entrant 29 finishes and entrant finishes and \(t_{29} > t_{65}\).
\end{itemize}

Of these entrant 29 decisively wins only in the third and fourth
outcomes.

In order to evaluate the probability that entrant 29 wins we'll need to
make careful use of conditional probability theory taking into account
all of these outcomes, \begin{align*}
\pi( &\text{Entrant 29 beats entrant 65 } )
\\
&=\quad\;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 1)
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 0)
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 0 )
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1)
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0, t_{29} < t_{65})
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                      t_{29} < t_{65})
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0, t_{29} > t_{65})
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                       t_{29} > t_{65})
\\
&=\quad\;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 0
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 0
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 0 )
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 1
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 1
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                       t_{29} < t_{65})
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 0
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                       t_{29} > t_{65}),
\end{align*} or \begin{align*}
\pi( &\text{Entrant 29 beats entrant 65 } )
\\
&=\quad \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad + \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
              t_{29} < t_{65})
\\
&=\quad \;\,
\pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad\ + \; \pi( t_{29} < t_{65} \mid
                  \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0 )
\\
&\quad\quad \cdot \pi(\mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0)
\\
&=\quad \;\,
p_{\text{forfeit win}}
\\
&\quad\ + \; \pi( t_{29} < t_{65} \mid
                  \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0 )
\cdot p_{\text{no forfeits}}.
\end{align*}

At that is left is using Markov chain Monte Carlo to estimate the three
posterior predictive probabilities on the right-hand side and then
combine them together to give the left-hand side.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e1 }\OtherTok{\textless{}{-}} \DecValTok{29}
\NormalTok{status\_name1 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_statuses\_pred["}\NormalTok{, e1, }\StringTok{"]"}\NormalTok{)}
\NormalTok{time\_name1 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_f\_times\_pred["}\NormalTok{, e1, }\StringTok{"]"}\NormalTok{)}

\NormalTok{e2 }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{status\_name2 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_statuses\_pred["}\NormalTok{, e2, }\StringTok{"]"}\NormalTok{)}
\NormalTok{time\_name2 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_f\_times\_pred["}\NormalTok{, e2, }\StringTok{"]"}\NormalTok{)}

\NormalTok{eval\_forfeit\_win }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(status1, status2) \{}
  \FunctionTok{as.numeric}\NormalTok{(status1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ status2 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
\NormalTok{\}}
\NormalTok{forfeit\_win\_samples }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{eval\_expectand\_pushforward}\NormalTok{(samples,}
\NormalTok{                                  eval\_forfeit\_win,}
                                  \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}status1\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name1,}
                                       \StringTok{\textquotesingle{}status2\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name2))}
\NormalTok{p\_forfeit\_win }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(forfeit\_win\_samples)[}\DecValTok{1}\NormalTok{]}

\NormalTok{eval\_no\_forfeits }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(status1, status2) \{}
  \FunctionTok{as.numeric}\NormalTok{(status1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ status2 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)}
\NormalTok{\}}
\NormalTok{no\_forfeits\_samples }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{eval\_expectand\_pushforward}\NormalTok{(samples,}
\NormalTok{                                  eval\_no\_forfeits,}
                                  \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}status1\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name1,}
                                       \StringTok{\textquotesingle{}status2\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name2))}
\NormalTok{p\_no\_forfeits }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(no\_forfeits\_samples)[}\DecValTok{1}\NormalTok{]}

\NormalTok{time\_comp }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(t1, t2) \{}
  \FunctionTok{as.numeric}\NormalTok{(t1 }\SpecialCharTok{\textless{}}\NormalTok{ t2)}
\NormalTok{\}}
\NormalTok{neg\_time\_diff\_samples }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{eval\_expectand\_pushforward}\NormalTok{(samples,}
\NormalTok{                                  time\_comp,}
                                  \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}t1\textquotesingle{}} \OtherTok{=}\NormalTok{ time\_name1,}
                                       \StringTok{\textquotesingle{}t2\textquotesingle{}} \OtherTok{=}\NormalTok{ time\_name2))}
\NormalTok{p\_neg\_time\_diff }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(neg\_time\_diff\_samples)[}\DecValTok{1}\NormalTok{]}


\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ p\_forfeit\_win }\SpecialCharTok{+}\NormalTok{ p\_neg\_time\_diff }\SpecialCharTok{*}\NormalTok{ p\_no\_forfeits}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Probability that entrant \%i beats entrant \%i = \%.3f"}\NormalTok{,}
\NormalTok{            e1, e2, p))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Probability that entrant 29 beats entrant 65 = 0.734
\end{verbatim}

Although entrant 29 is definitely favored the outcome is by no means
certain!

\section{Conclusion}\label{conclusion}

Although the domain of this analysis might be a bit obscure the best
practices that it demonstrates are fundamental. By understanding the
provenance of the data we can motivate an initial probabilistic model
and then iteratively improve it until we can no longer resolve any model
inadequacies. The inferences from the final model not only provide a
variety of insights about the source of the data but also allow inform
all kinds of predictions that might be of practical relevance.

Being able to wax nostalgic about the glory days of the Super Nintendo
Entertainment System® and celebrate the capabilities of open source
projects along the communities they inspire along the way is just a
pleasant bonus.

\section*{Acknowledgements}\label{acknowledgements}
\addcontentsline{toc}{section}{Acknowledgements}

I thank jd for helpful comments.

A very special thanks to everyone supporting me on Patreon: Adam
Fleischhacker, Adriano Yoshino, Alejandro Navarro-Martínez, Alessandro
Varacca, Alex D, Alexander Noll, Alexander Rosteck, Andrea Serafino,
Andrew Mascioli, Andrew Rouillard, Andrew Vigotsky, Ara Winter, Austin
Rochford, Avraham Adler, Ben Matthews, Ben Swallow, Benoit Essiambre,
Bertrand Wilden, Bradley Kolb, Brandon Liu, Brendan Galdo, Brynjolfur
Gauti Jónsson, Cameron Smith, Canaan Breiss, Cat Shark, CG, Charles
Naylor, Chase Dwelle, Chris Jones, Christopher Mehrvarzi, Colin Carroll,
Colin McAuliffe, Damien Mannion, dan mackinlay, Dan W Joyce, Dan Waxman,
Dan Weitzenfeld, Daniel Edward Marthaler, Daniel Saunders, Darshan
Pandit, Darthmaluus , David Galley, David Wurtz, Doug Rivers, Dr.~Jobo,
Dr.~Omri Har Shemesh, Dylan Maher, Ed Cashin, Edgar Merkle, Eric
LaMotte, Ero Carrera, Eugene O'Friel, Felipe González, Fergus Chadwick,
Finn Lindgren, Florian Wellmann, Geoff Rollins, Håkan Johansson, Hamed
Bastan-Hagh, Hauke Burde, Hector Munoz, Henri Wallen, hs, Hugo Botha,
Ian, Ian Costley, idontgetoutmuch, Ignacio Vera, Ilaria Prosdocimi,
Isaac Vock, Isidor Belic, J, J Michael Burgess, jacob pine, Jair
Andrade, James C, James Hodgson, James Wade, Janek Berger, Jason Martin,
Jason Pekos, Jason Wong, jd, Jeff Burnett, Jeff Dotson, Jeff Helzner,
Jeffrey Erlich, Jessica Graves, Joe Sloan, Joe Wagner, John Flournoy,
Jonathan H. Morgan, Jonathon Vallejo, Joran Jongerling, JU, June, Justin
Bois, Kádár András, Karim Naguib, Karim Osman, Kejia Shi, Kristian
Gårdhus Wichmann, Lars Barquist, lizzie , Logan Sullivan, LOU ODETTE,
Luís F, Marcel Lüthi, Marek Kwiatkowski, Mark Donoghoe, Markus P.,
Márton Vaitkus, Matt Moores, Matthew, Matthew Kay, Matthieu LEROY,
Mattia Arsendi, Maurits van der Meer, Michael Colaresi, Michael DeWitt,
Michael Dillon, Michael Lerner, Mick Cooney, Mike Lawrence, N Sanders,
N.S. , Name, Nathaniel Burbank, Nic Fishman, Nicholas Clark, Nicholas
Cowie, Nick S, Octavio Medina, Ole Rogeberg, Oliver Crook, Patrick
Kelley, Patrick Boehnke, Pau Pereira Batlle, Peter Johnson, Pieter van
den Berg , ptr, Ramiro Barrantes Reynolds, Raúl Peralta Lozada, Ravin
Kumar, Rémi , Rex Ha, Riccardo Fusaroli, Richard Nerland, Robert Frost,
Robert Goldman, Robert kohn, Robin Taylor, Ryan Grossman, Ryan Kelly, S
Hong, Sean Wilson, Sergiy Protsiv, Seth Axen, shira, Simon Duane, Simon
Lilburn, sssz, Stan\_user, Stephen Lienhard, Stew Watts, Stone Chen,
Susan Holmes, Svilup, Tao Ye, Tate Tunstall, Tatsuo Okubo, Teresa Ortiz,
Theodore Dasher, Thomas Siegert, Thomas Vladeck, Tobychev , Tomáš Frýda,
Tony Wuersch, Virginia Fisher, Vladimir Markov, Wil Yegelwel, Will Farr,
woejozney, yolhaj , yureq , Zach A, Zad Rafi, and Zhengchen Cai.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-MapRando:2024}
{``Super Metroid Map Rando.''} n.d.

\bibitem[\citeproctext]{ref-RacetimeSMR:2024}
{``Super Metroid Randomizer \textbar{} Racetime.gg.''} n.d.

\end{CSLReferences}

\section*{License}\label{license}
\addcontentsline{toc}{section}{License}

A repository containing all of the files used to generate this chapter
is available on
\href{https://github.com/betanalpha/quarto_chapters/tree/main/case_studies/racing}{GitHub}.

The code in this case study is copyrighted by Michael Betancourt and
licensed under the new BSD (3-clause) license:

\url{https://opensource.org/licenses/BSD-3-Clause}

The text and figures in this chapter are copyrighted by Michael
Betancourt and licensed under the CC BY-NC 4.0 license:

\url{https://creativecommons.org/licenses/by-nc/4.0/}

\section*{Original Computing
Environment}\label{original-computing-environment}
\addcontentsline{toc}{section}{Original Computing Environment}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{writeLines}\NormalTok{(}\FunctionTok{readLines}\NormalTok{(}\FunctionTok{file.path}\NormalTok{(}\FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"HOME"}\NormalTok{), }\StringTok{".R/Makevars"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
CC=clang

CXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function -Wno-macro-redefined -Wno-unneeded-internal-declaration
CXX=clang++ -arch x86_64 -ftemplate-depth-256

CXX14FLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function -Wno-macro-redefined -Wno-unneeded-internal-declaration -Wno-unknown-pragmas
CXX14=clang++ -arch x86_64 -ftemplate-depth-256
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
R version 4.3.2 (2023-10-31)
Platform: x86_64-apple-darwin20 (64-bit)
Running under: macOS Sonoma 14.4.1

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/New_York
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] colormap_0.1.4     rstan_2.32.6       StanHeaders_2.32.7

loaded via a namespace (and not attached):
 [1] gtable_0.3.4       jsonlite_1.8.8     compiler_4.3.2     Rcpp_1.0.11       
 [5] parallel_4.3.2     gridExtra_2.3      scales_1.3.0       yaml_2.3.8        
 [9] fastmap_1.1.1      ggplot2_3.4.4      R6_2.5.1           curl_5.2.0        
[13] knitr_1.45         tibble_3.2.1       munsell_0.5.0      pillar_1.9.0      
[17] rlang_1.1.2        utf8_1.2.4         V8_4.4.1           inline_0.3.19     
[21] xfun_0.41          RcppParallel_5.1.7 cli_3.6.2          magrittr_2.0.3    
[25] digest_0.6.33      grid_4.3.2         lifecycle_1.0.4    vctrs_0.6.5       
[29] evaluate_0.23      glue_1.6.2         QuickJSR_1.0.8     codetools_0.2-19  
[33] stats4_4.3.2       pkgbuild_1.4.3     fansi_1.0.6        colorspace_2.1-0  
[37] rmarkdown_2.25     matrixStats_1.2.0  tools_4.3.2        loo_2.6.0         
[41] pkgconfig_2.0.3    htmltools_0.5.7   
\end{verbatim}



\end{document}
